{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VU50VMUOFEYo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from numpy import load, save, savez"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Devanagari Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "FFDjDOHgN8Ub",
        "outputId": "3156ecb6-65bb-4a0b-c6ef-4d9f2fceaf54"
      },
      "outputs": [],
      "source": [
        "# x_train_deva = load('../../Dataset/To use/Devanagari/x_train_deva_new.npy')\n",
        "# x_test_deva = load('../../Dataset/To use/Devanagari/x_test_deva_new.npy')\n",
        "# y_train_deva = load('../../Dataset/To use/Devanagari/y_train_deva_new.npy')\n",
        "# y_test_deva = load('../../Dataset/To use/Devanagari/y_test_deva_new.npy')\n",
        "data = load('../../Dataset/To use/Devanagari/Devanagari.npz')\n",
        "x_train_deva = data[data.files[0]]\n",
        "x_test_deva = data[data.files[1]]\n",
        "y_train_deva = data[data.files[2]]\n",
        "y_test_deva = data[data.files[3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(80000, 28, 28, 3)\n",
            "(20000, 28, 28, 3)\n",
            "(80000,)\n",
            "(20000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_deva.shape)\n",
        "print(x_test_deva.shape)\n",
        "print(y_train_deva.shape)\n",
        "print(y_test_deva.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_deva = tf.expand_dims(x_train_deva, axis=3, name=None)\n",
        "x_test_deva = tf.expand_dims(x_test_deva, axis=3, name=None)\n",
        "x_train_deva = tf.repeat(x_train_deva, 3, axis=3)\n",
        "x_test_deva = tf.repeat(x_test_deva, 3, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "savez('../../Dataset/To use/Devanagari/Devanagari', x_train_deva=x_train_deva, x_test_deva = x_test_deva, y_train_deva = y_train_deva, y_test_deva = y_test_deva)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7    10000\n",
              "3    10000\n",
              "2    10000\n",
              "9    10000\n",
              "5    10000\n",
              "1    10000\n",
              "6    10000\n",
              "8    10000\n",
              "4    10000\n",
              "0    10000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_deva = pd.DataFrame(np.concatenate((y_train_deva, y_test_deva)))\n",
        "df_deva[0].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Bangla Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x_train_kan = load('../../Dataset/To use/Kannada/x_train_kan_new.npy')\n",
        "# x_test_kan = load('../../Dataset/To use/Kannada/x_test_kan_new.npy')\n",
        "# y_train_kan = load('../../Dataset/To use/Kannada/y_train_kan_new.npy')\n",
        "# y_test_kan = load('../../Dataset/To use/Kannada/y_test_kan_new.npy')\n",
        "\n",
        "data = load('../../Dataset/To use/Bengali.npz')\n",
        "x_train_ben = data[data.files[0]]\n",
        "x_test_ben = data[data.files[1]]\n",
        "y_train_ben = data[data.files[2]]\n",
        "y_test_ben = data[data.files[3]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "savez('../../Dataset/To use/Bengali/Bengali', x_train_ben=x_train_ben,x_test_ben=x_test_ben, y_train_ben=y_train_ben, y_test_ben=y_test_ben)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(80000, 28, 28, 3)\n",
            "(20000, 28, 28, 3)\n",
            "(80000,)\n",
            "(20000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_ben.shape)\n",
        "print(x_test_ben.shape)\n",
        "print(y_train_ben.shape)\n",
        "print(y_test_ben.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    10000\n",
              "0    10000\n",
              "5    10000\n",
              "4    10000\n",
              "3    10000\n",
              "1    10000\n",
              "8    10000\n",
              "9    10000\n",
              "7    10000\n",
              "6    10000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_kan = pd.DataFrame(np.concatenate((y_train_ben, y_test_ben)))\n",
        "df_kan[0].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Arabic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x_train_arb = load('../../Dataset/To use/Arabic/x_train_arb_new.npy')\n",
        "# x_test_arb = load('../../Dataset/To use/Arabic/x_test_arb_new.npy')\n",
        "# y_train_arb = load('../../Dataset/To use/Arabic/y_train_arb_new.npy')\n",
        "# y_test_arb = load('../../Dataset/To use/Arabic/y_test_arb_new.npy')\n",
        "\n",
        "data = load('../../Dataset/To use/Arabic/Arabic.npz')\n",
        "x_train_arb = data[data.files[0]]\n",
        "x_test_arb = data[data.files[1]]\n",
        "y_train_arb = data[data.files[2]]\n",
        "y_test_arb = data[data.files[3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_arb = tf.expand_dims(x_train_arb, axis=3, name=None)\n",
        "x_test_arb = tf.expand_dims(x_test_arb, axis=3, name=None)\n",
        "x_train_arb = tf.repeat(x_train_arb, 3, axis=3)\n",
        "x_test_arb = tf.repeat(x_test_arb, 3, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "savez('../../Dataset/To use/Arabic/Arabic', x_train_arb=x_train_arb, x_test_arb=x_test_arb, y_train_arb=y_train_arb, y_test_arb=y_test_arb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(80000, 28, 28, 3)\n",
            "(20000, 28, 28, 3)\n",
            "(80000,)\n",
            "(20000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_arb.shape)\n",
        "print(x_test_arb.shape)\n",
        "print(y_train_arb.shape)\n",
        "print(y_test_arb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    10000\n",
              "1    10000\n",
              "2    10000\n",
              "3    10000\n",
              "4    10000\n",
              "5    10000\n",
              "6    10000\n",
              "7    10000\n",
              "8    10000\n",
              "9    10000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_arabic = pd.DataFrame(np.concatenate((y_train_arb, y_test_arb)))\n",
        "df_arabic[0].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "calb-ru9PKtE",
        "outputId": "d2d63723-bd24-4de7-8cd3-8d08fa8d55a4"
      },
      "outputs": [],
      "source": [
        "# x_train_eng = load('../../Dataset/To use/English/x_train_eng_new.npy')\n",
        "# x_test_eng = load('../../Dataset/To use/English/x_test_eng_new.npy')\n",
        "# y_train_eng = load('../../Dataset/To use/English/y_train_eng_new.npy')\n",
        "# y_test_eng = load('../../Dataset/To use/English/y_test_eng_new.npy')\n",
        "\n",
        "data = load('../../Dataset/To use/English/English.npz')\n",
        "x_train_eng = data[data.files[0]]\n",
        "x_test_eng = data[data.files[1]]\n",
        "y_train_eng = data[data.files[2]]\n",
        "y_test_eng = data[data.files[3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_eng = tf.expand_dims(x_train_eng, axis=3, name=None)\n",
        "x_test_eng = tf.expand_dims(x_test_eng, axis=3, name=None)\n",
        "x_train_eng = tf.repeat(x_train_eng, 3, axis=3)\n",
        "x_test_eng = tf.repeat(x_test_eng, 3, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz8C9sMiyQz3",
        "outputId": "dea942bd-62b5-4aa4-ba5b-df1d39d4e358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(80000, 28, 28, 3)\n",
            "(20000, 28, 28, 3)\n",
            "(80000,)\n",
            "(20000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_eng.shape)\n",
        "print(x_test_eng.shape)\n",
        "print(y_train_eng.shape)\n",
        "print(y_test_eng.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "savez('../../Dataset/To use/English/English', x_train_eng=x_train_eng,\n",
        "      x_test_eng=x_test_eng, y_train_eng=y_train_eng, y_test_eng=y_test_eng)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5    10000\n",
              "0    10000\n",
              "4    10000\n",
              "1    10000\n",
              "9    10000\n",
              "2    10000\n",
              "3    10000\n",
              "6    10000\n",
              "7    10000\n",
              "8    10000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_eng = pd.DataFrame(np.concatenate((y_train_eng, y_test_eng)))\n",
        "df_eng[0].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Telugu Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x_train_tel = load('../../Dataset/To use/Telugu/x_train_tel_new.npy')\n",
        "# x_test_tel = load('../../Dataset/To use/Telugu/x_test_tel_new.npy')\n",
        "# y_train_tel = load('../../Dataset/To use/Telugu/y_train_tel_new.npy')\n",
        "# y_test_tel = load('../../Dataset/To use/Telugu/y_test_tel_new.npy')\n",
        "\n",
        "data = load('../../Dataset/To use/Telugu/Telugu.npz')\n",
        "x_train_tel = data[data.files[0]]\n",
        "x_test_tel = data[data.files[1]]\n",
        "y_train_tel = data[data.files[2]]\n",
        "y_test_tel = data[data.files[3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_tel = tf.expand_dims(x_train_tel, axis=3, name=None)\n",
        "x_test_tel = tf.expand_dims(x_test_tel, axis=3, name=None)\n",
        "x_train_tel = tf.repeat(x_train_tel, 3, axis=3)\n",
        "x_test_tel = tf.repeat(x_test_tel, 3, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "savez('../../Dataset/To use/Telugu/Telugu', x_train_tel=x_train_tel, x_test_tel=x_test_tel, y_train_tel=y_train_tel, y_test_tel=y_test_tel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(80000, 28, 28, 3)\n",
            "(20000, 28, 28, 3)\n",
            "(80000,)\n",
            "(20000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_tel.shape)\n",
        "print(x_test_tel.shape)\n",
        "print(y_train_tel.shape)\n",
        "print(y_test_tel.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3    10000\n",
              "8    10000\n",
              "1    10000\n",
              "9    10000\n",
              "7    10000\n",
              "6    10000\n",
              "0    10000\n",
              "4    10000\n",
              "2    10000\n",
              "5    10000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tel = pd.DataFrame(np.concatenate((y_train_tel, y_test_tel)))\n",
        "df_tel[0].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging all 5 together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwdydCXTVS8q",
        "outputId": "f718d6b8-090c-488b-b9bb-e80417aed511"
      },
      "outputs": [],
      "source": [
        "# TEKA\n",
        "# X_train = np.concatenate((x_train_kan, x_train_eng, x_train_tel, x_train_arb))\n",
        "# X_test = np.concatenate((x_test_kan, x_test_eng, x_test_tel, x_test_arb))\n",
        "# Y_train = np.concatenate((y_train_kan, y_train_eng, y_train_tel, y_train_arb))\n",
        "# Y_test = np.concatenate((y_test_kan, y_test_eng, y_test_tel, y_test_arb))\n",
        "\n",
        "\n",
        "# THEK\n",
        "# X_train = np.concatenate((x_train_deva, x_train_kan, x_train_eng, x_train_tel))\n",
        "# X_test = np.concatenate((x_test_deva, x_test_kan, x_test_eng, x_test_tel))\n",
        "# Y_train = np.concatenate((y_train_deva, y_train_kan, y_train_eng, y_train_tel))\n",
        "# Y_test = np.concatenate((y_test_deva, y_test_kan, y_test_eng, y_test_tel))\n",
        "\n",
        "# HEKA\n",
        "# X_train = np.concatenate((x_train_deva, x_train_kan, x_train_eng, x_train_arb))\n",
        "# X_test = np.concatenate((x_test_deva, x_test_kan, x_test_eng, x_test_arb))\n",
        "# Y_train = np.concatenate((y_train_deva, y_train_kan, y_train_eng, y_train_arb))\n",
        "# Y_test = np.concatenate((y_test_deva, y_test_kan, y_test_eng, y_test_arb))\n",
        "\n",
        "# HEAT\n",
        "# X_train = np.concatenate((x_train_deva, x_train_arb, x_train_eng, x_train_tel))\n",
        "# X_test = np.concatenate((x_test_deva, x_test_arb, x_test_eng, x_test_tel))\n",
        "# Y_train = np.concatenate((y_train_deva, y_train_arb, y_train_eng, y_train_tel))\n",
        "# Y_test = np.concatenate((y_test_deva, y_test_arb, y_test_eng, y_test_tel))\n",
        "\n",
        "# BHEAT\n",
        "X_train = np.concatenate((x_train_deva, x_train_arb, x_train_eng, x_train_tel, x_train_ben))\n",
        "X_test = np.concatenate((x_test_deva, x_test_arb, x_test_eng, x_test_tel, x_test_ben))\n",
        "Y_train = np.concatenate((y_train_deva, y_train_arb, y_train_eng, y_train_tel, y_train_ben))\n",
        "Y_test = np.concatenate((y_test_deva, y_test_arb, y_test_eng, y_test_tel, y_test_ben))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(400000, 28, 28, 3)\n",
            "(100000, 28, 28, 3)\n",
            "(400000,)\n",
            "(100000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt5KG_CBa1XY",
        "outputId": "af61523d-1b88-4cdd-876c-281bf8a80a68"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import savez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "savez('../../Dataset/To use/combined/BHEAT', x_train = X_train, x_test = X_test, y_train = Y_train, y_test = Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
